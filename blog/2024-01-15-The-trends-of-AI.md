---
slug: The Trends of AI
title: 【翻译】人工智能的几点趋势
authors: taoshengshi
tags: [人工智能, 趋势]
---

# 【翻译】人工智能的几点趋势
关于AI的发展现状和未来展望，我的几点看法。

原文：     
Making sense of the current state of AI | @adlrocha
https://www.adlrocha.com/blog/2024-01-10-state-ai/

## LLM和基础模型正在成为一种商品
从头开始训练LLM是非常昂贵的，只有少数财力雄厚、能够获得大量硬件的公司能够做到这一点(感受一下规模：phi-2，一个带有2.7B参数的“小型”LLM花了微软14天时间和96个A100 GPU)。幸运的是，已经有几个开放的基础模型了。开发人员、研究人员和新创业公司已经在现有开源基础模型的基础上做出了令人惊叹的事情。这些模型已经产生了前所未有的影响，并成为真正创新的新用例的核心。

## 通过微调基础模型来构建垂直代理是下一个前沿领域
虽然小型团队和开发人员可能无法训练他们自己的基础模型，但他们仍然可以构建真正的创新模型来解决垂直领域(而不是那么狭窄)的问题。像OpenAI或谷歌这样的公司可能正在向AGI发展，但我觉得通过AI和LLM解决小众日常问题仍然有很大的价值。为此，我们不需要AGI或真正强大的基础模型，现有开源基础模型的微调版本可能正是这个问题所需要的。通过构建非常好的特定于任务的模型，我们可以构建未来能够协作完成更复杂任务的小型代理(也许这是通往AGI的实际路径?)。已经有一些公司是建立在这种特定于任务的代理之上的，比如Fixie.ai，用于通用代理的构建和编排。还有Luzia，作为在基础模型之上构建的特定于用例代理的一个很好的例子。

## LLM和基础模型的应用还在探索之中
我不知道读者如何思考，但AI作为一种技术的未来用例和影响显然比区块链技术要清晰得多。我仍然觉得我们处于LLM、生成模型和几乎每天都在发布的所有新创新的应用探索阶段。生成模型已经创造出了令人惊叹的图像，并展现出真正的智慧和创造力。我们发现了一种新的超能力，但我不确定我们是否找到了使用它的最佳方式。ChatGPT等正在成为我们日常生活的神奇助手，但它们还不如一个好的谷歌搜索或一个深思熟虑、解释清楚的Stack Overflow帖子那么好。

## 产品级LLM应用的扩展性和部署是困难的
我记得几年前在Jupyter Notebooks中发生了许多AI创新。在Atari游戏(以及任意类型视频的图像识别系统等)中击败人类的RL模型。所有这些工作对于推进最先进的技术非常有用，但在许多情况下，这些开发无法通过iron测试，无法在生产环境扩展。我认为这是AI短期/中期最紧迫的问题之一，也是研究人员、工程师和公司明年最关注的问题之一。为了能够在任何地方运行LLM和AI模型，能够根据前大型科技公司当前的硬件能力进行扩展，将需要：更好的量化、边缘运行模型、去中心化AI、改进网络堆栈、GPU性能以及许多其它正在进行的创新理念。我的感觉是，非AI专家在这个领域也有贡献的空间：从分布式系统工程师到编译器、DevOps和后端工程师。[GitData.AI](https://gitdata.ai)团队的工作可以了解一下。

## 对齐(Alignment)是值得担心的
不仅性能是一个问题，安全性和隐私性也是一个问题。我不知道读者怎么想，但从长远来看，这确实是我担心的事情。在安全方面，有很多事情可能会出错，而我们可能没有意识到：从模型中的个人信息泄露，到更具灾难性和存在性的风险相关问题。一旦我们开始将复杂的AI模型与互联网和其他实时信息源连接起来，并为它们提供与现实世界互动的杠杆，事情可能很快就会变得一团糟。如上所述，我们发现了一种新的超能力，就像电、火或互联网一样，我们知道AI的影响是巨大的，但我们仍然不知道如何使用它，以及它可能产生的所有有害影响。我决定再次跟上AI的步伐的原因之一是，我想开始更积极地为AI校准问题做出贡献。

## AI仍然需要人类参与其中
生成模型需要新的内容来提高它们的性能，根据最近的研究，我们可能会耗尽训练这些模型的所有有用数据。我们最终可能会从数据集大小而不是计算的角度达到规模定律(scaling laws)的极限。这意味着AI仍然需要人类创造更多的数据，AI可以消费这些数据来改善其训练(只要我们还没有找到一种有效地利用人工数据来改善AI模型训练的方法，这也是一个活跃的研究方向)。幸运的是，至少在一段时间内，AI可能仍然需要我们。
![](./img/scaling-laws.png)
`规模定律的说明`

